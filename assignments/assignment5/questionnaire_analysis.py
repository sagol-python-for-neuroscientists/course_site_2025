import json
from pathlib import Path
from typing import Union, Tuple
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Outside helper functions:
def is_valid_email(email: str) -> bool:
    if not isinstance(email, str):
        return False
    if email.count("@") != 1:
        return False
    if email.startswith("@") or email.endswith("@"):
        return False
    if "." not in email or email.startswith(".") or email.endswith("."):
        return False

    local, domain = email.split("@")
    print(f"Validating email: {email}")
    if not local or not domain:
        return False
    if domain.startswith("."):
        return False
    if " " in email:
        return False

    return True


class QuestionnaireAnalysis:
    """
    Reads and analyzes data generated by the questionnaire experiment.
    Should be able to accept strings and pathlib.Path objects.
    """

    def __init__(self, data_fname: Union[Path, str]):
        self.data_fname = Path(data_fname)
        if not self.data_fname.exists():
            raise ValueError(f"File not found: {self.data_fname}")
        self.data = None

    def read_data(self):
        """Reads the json data located in self.data_fname into memory, to
        the attribute self.data.
        """
        with open(self.data_fname, 'r') as f:
            self.data = pd.DataFrame(json.load(f))

    def show_age_distrib(self) -> Tuple[np.ndarray, np.ndarray]:
        # Convert to numeric, forcing errors to NaN
        ages = pd.to_numeric(self.data["age"], errors="coerce")

        # Remove invalid ages: NaN, negative, over 120
        clean_ages = ages.dropna()
        clean_ages = clean_ages[(clean_ages >= 0) & (clean_ages <= 120)]
        # Define bins: [0,10), [10,20), ..., [90,100]
        bins = np.arange(0, 110, 10)  # 0 to 100 inclusive upper edge
        hist, bin_edges = np.histogram(clean_ages, bins=bins)

        # Plot
        plt.figure(figsize=(8, 5))
        plt.hist(clean_ages, bins=bins, edgecolor='black')
        plt.title("Age Distribution of Participants")
        plt.xlabel("Age")
        plt.ylabel("Number of Participants")
        plt.grid(True)
        plt.tight_layout()
        plt.show()

        return hist, bin_edges


    def remove_rows_without_mail(self) -> pd.DataFrame:
        """Checks self.data for rows with invalid emails, and removes them.

        Returns
        -------
        df : pd.DataFrame
            A corrected DataFrame, i.e. the same table but with the erroneous rows removed and
            the (ordinal) index after a reset.
        """
        valid_mask = self.data["email"].apply(is_valid_email)
        cleaned_df = self.data[valid_mask].reset_index(drop=True)
        return cleaned_df


    def fill_na_with_mean(self) -> Tuple[pd.DataFrame, np.ndarray]:
        """Finds, in the original DataFrame, the subjects that didn't answer
        all questions, and replaces that missing value with the mean of the
        other grades for that student.

        Returns
        -------
        df : pd.DataFrame
            The corrected DataFrame after insertion of the mean grade
        arr : np.ndarray
            Row indices of the students that their new grades were generated
        """
        # Work on a copy to avoid modifying original
        df = self.data.copy()

        # Ensure question columns are numeric
        question_cols = ['q1', 'q2', 'q3', 'q4', 'q5']
        for col in question_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        # Identify rows with at least one NaN
        missing_mask = df[question_cols].isna().any(axis=1)

        # Apply row-wise function to fill NaNs with the row mean, rounded up to 1 decimal place
        def fill_row_with_mean(row):
            mean = np.round(row.dropna().mean(), 1)
            return row.fillna(mean)

        df.loc[missing_mask, question_cols] = df.loc[missing_mask, question_cols].apply(fill_row_with_mean, axis=1)

        # Return corrected DataFrame and affected row indices
        corrected_indices = df.index[missing_mask].to_numpy()
        return df, corrected_indices


    def score_subjects(self, maximal_nans_per_sub: int = 1) -> pd.DataFrame:
        """Calculates the average score of a subject and adds a new "score" column with it."""

        df = self.data.copy()
        question_cols = ['q1', 'q2', 'q3', 'q4', 'q5']

        # Ensure numeric types for grading columns
        for col in question_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        # Count number of NaNs per row
        nan_counts = df[question_cols].isna().sum(axis=1)
        print(f"NaN counts per row: {nan_counts[nan_counts > 1].count()} rows with more than 1 NaN")
        # Compute mean score across non-NaN grades
        mean_scores = df[question_cols].mean(axis=1, skipna=True)

        # Round down and convert to integer (as float → int)
        int_scores = np.floor(mean_scores).astype("UInt8")

        # If too many NaNs → assign pd.NA
        df["score"] = int_scores
        df.loc[nan_counts > maximal_nans_per_sub, "score"] = pd.NA

        return df


    def correlate_gender_age(self, plot: bool = False) -> pd.DataFrame:
        """
        Looks for a correlation between the gender of the subject, their age
        and the score for all five questions.

        Returns
        -------
        pd.DataFrame
            A DataFrame with a MultiIndex containing the gender and whether the subject is above
            40 years of age, and the average score in each of the five questions.
        """
        df = self.data.copy()

        # Ensure numeric columns and clean age
        df['age'] = pd.to_numeric(df['age'], errors='coerce')
        question_cols = ['q1', 'q2', 'q3', 'q4', 'q5']
        for col in question_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        # Drop rows where age or gender is missing
        df = df.dropna(subset=['age', 'gender'])
        print(f"shape of data after dropping NaNs: {df.shape}")
        # Part (a): set MultiIndex [original index, gender, age]
        df.index = pd.MultiIndex.from_tuples(
            [(i, row['gender'], row['age']) for i, row in df.iterrows()],
            names=['idx', 'gender', 'age']
        )
        df = df.drop(columns=['gender', 'age'])

        # Part (b): group by gender and whether age > 40
        df['age_above_40'] = df.index.get_level_values('age') > 40

        # Part (c): group and compute mean per question
        grouped = df.groupby(['gender', 'age_above_40'])[question_cols].mean()
        grouped.index.set_names(['gender', 'age'], inplace=True)

        if plot:
            ax = grouped.plot(kind='bar', figsize=(12, 6), width=0.8)
            ax.set_ylabel("Grade score")
            ax.set_title("Average question results for different groups of participants (True means above 40)")
            ax.legend(title="Question")
            ax.grid(axis='y')
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            plt.show()
        return grouped

if __name__ == "__main__":
    # Example usage
    current_dir = Path(__file__).parent
    fname = current_dir / 'data.json'   
    q = QuestionnaireAnalysis(fname)
    q.read_data()

    print(q.data.head())
    # print(q.data.shape)
    # print(q.data.columns)
    # print(q.data.info())
    # print(q.data.isna().sum())
    # print(q.data.describe(include='all'))

    # show age distribution
    # hist, edges = q.show_age_distrib()

    # Remove rows without valid emails
    # q.data = q.remove_rows_without_mail()
    # print(q.data.shape)

    # # Fill missing values with mean
    # filled_df, filled_indices = q.fill_na_with_mean()
    # print("Filled DataFrame with mean values:")
    # print(filled_df.head())
    # print("Indices of filled rows:", filled_indices)
    # print(q.data.shape)

    # Score subjects
    # scored_df = q.score_subjects()
    # print("Scored DataFrame:")
    # print(scored_df.head())
    # print(scored_df.shape)
    # print number of rows with score = NA
    
    # apply correlate_gender_age
    # grouped_df = q.correlate_gender_age()
    # print(grouped_df)
